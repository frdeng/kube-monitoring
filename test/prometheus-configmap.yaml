apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-conf
data:
  prometheus.yml: |
    # this is my global config
    global:
      scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
      evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
      # scrape_timeout is set to the global default (10s).
    
    # Alertmanager configuration
    alerting:
      alertmanagers:
      - static_configs:
        - targets:
          # - alertmanager:9093
    
    # Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
    rule_files:
      # - "first_rules.yml"
      # - "second_rules.yml"
    
    # A scrape configuration containing exactly one endpoint to scrape:
    # Here it's Prometheus itself.
    scrape_configs:
      # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
      - job_name: 'prometheus'
    
        # metrics_path defaults to '/metrics'
        # scheme defaults to 'http'.
    
        static_configs:
        - targets: ['localhost:9090']


      # Scrape some pods (for daemon sets)
      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
        - api_servers:
          - 'https://kubernetes.default.svc.cluster.local'
          in_cluster: true
          role: pod
      
        # You can specify the following annotations (on pods):
        #   prometheus.io.scrape: true - scrape this pod
        #   prometheus.io.port - scrape this port
        relabel_configs:
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_pod_namespace, __meta_kubernetes_pod_label_name]
          separator: '/'
          target_label: job
        - source_labels: [__meta_kubernetes_pod_node_name]
          target_label: node
